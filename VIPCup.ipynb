{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-18T07:36:47.764527Z",
     "iopub.status.busy": "2023-08-18T07:36:47.763922Z",
     "iopub.status.idle": "2023-08-18T07:36:48.831100Z",
     "shell.execute_reply": "2023-08-18T07:36:48.830050Z",
     "shell.execute_reply.started": "2023-08-18T07:36:47.764493Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:36:48.838492Z",
     "iopub.status.busy": "2023-08-18T07:36:48.836216Z",
     "iopub.status.idle": "2023-08-18T07:36:53.571838Z",
     "shell.execute_reply": "2023-08-18T07:36:53.570865Z",
     "shell.execute_reply.started": "2023-08-18T07:36:48.838456Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"encoder + classifier\"\"\"\n",
    "    def __init__(self, name='resnet101', num_classes=2):  # Change 'resnet50' to 'resnet101'\n",
    "        super(ResNet, self).__init__()\n",
    "        if (name == 'resnet101'):  # Change the condition to 'resnet101'\n",
    "            self.encoder = torchvision.models.resnet101(zero_init_residual=True)  # Use resnet101\n",
    "            self.encoder.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "            self.encoder.fc = nn.Identity()\n",
    "            self.fc = nn.Linear(2048, num_classes)  # Update the input size to match ResNet-101\n",
    "        else:\n",
    "            self.encoder = torchvision.models.resnet18(zero_init_residual=True)\n",
    "            self.encoder.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "            self.encoder.fc = nn.Identity()\n",
    "            self.fc = nn.Linear(512, num_classes)\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.encoder(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:36:53.579530Z",
     "iopub.status.busy": "2023-08-18T07:36:53.576993Z",
     "iopub.status.idle": "2023-08-18T07:36:53.604589Z",
     "shell.execute_reply": "2023-08-18T07:36:53.602342Z",
     "shell.execute_reply.started": "2023-08-18T07:36:53.579491Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# datasets.py\n",
    "\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class OLIVES(data.Dataset):\n",
    "    def __init__(self,df, img_dir, transforms):\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "        self.df = pd.read_csv(df)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.img_dir + self.df.iloc[idx,0]\n",
    "        image = Image.open(path).convert(\"L\")\n",
    "        image = np.array(image)\n",
    "        image = Image.fromarray(image)\n",
    "        image = self.transforms(image)\n",
    "        b1 = self.df.iloc[idx,1]\n",
    "        b2 = self.df.iloc[idx,2]\n",
    "        b3 = self.df.iloc[idx,3]\n",
    "        b4 = self.df.iloc[idx, 4]\n",
    "        b5 = self.df.iloc[idx, 5]\n",
    "        b6 = self.df.iloc[idx, 6]\n",
    "        bio_tensor = torch.tensor([b1, b2, b3, b4, b5, b6])\n",
    "        return image, bio_tensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RECOVERY(data.Dataset):\n",
    "    def __init__(self,df, img_dir, transforms):\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "        self.df = pd.read_csv(df)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.img_dir + self.df.iloc[idx,0]\n",
    "        image = Image.open(path).convert(\"L\")\n",
    "        image = np.array(image)\n",
    "        image = Image.fromarray(image)\n",
    "        image = self.transforms(image)\n",
    "        return image\n",
    "\n",
    "\n",
    "\n",
    "class RECOVERY_TEST(data.Dataset):\n",
    "    def __init__(self,df, img_dir, transforms):\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "        self.df = pd.read_csv(df)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.img_dir + self.df.iloc[idx,0]\n",
    "        image = Image.open(path).convert(\"L\")\n",
    "        image = np.array(image)\n",
    "        image = Image.fromarray(image)\n",
    "        image = self.transforms(image)\n",
    "        b1 = self.df.iloc[idx,1]\n",
    "        b2 = self.df.iloc[idx,2]\n",
    "        b3 = self.df.iloc[idx,3]\n",
    "        b4 = self.df.iloc[idx, 4]\n",
    "        b5 = self.df.iloc[idx, 5]\n",
    "        b6 = self.df.iloc[idx, 6]\n",
    "        bio_tensor = torch.tensor([b1, b2, b3, b4, b5, b6])\n",
    "        return image, bio_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:36:53.612039Z",
     "iopub.status.busy": "2023-08-18T07:36:53.610407Z",
     "iopub.status.idle": "2023-08-18T07:36:53.634353Z",
     "shell.execute_reply": "2023-08-18T07:36:53.633267Z",
     "shell.execute_reply.started": "2023-08-18T07:36:53.612002Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# data_preprocessing.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "def combine_excel(csv_dir):\n",
    "    filenames = glob.glob(csv_dir + \"/*.xlsx\")\n",
    "    outputxlsx = pd.DataFrame()\n",
    "\n",
    "    for file in filenames:\n",
    "        df = pd.concat(pd.read_excel(file, sheet_name=None), ignore_index=True, sort=False)\n",
    "        outputxlsx = outputxlsx.append(df, ignore_index=True)\n",
    "\n",
    "    outputxlsx.to_csv('test_set_labels.csv',index=False)\n",
    "\n",
    "def analyze_dataframe(csv_dir):\n",
    "    pass\n",
    "\n",
    "def process_images(csv_dir):\n",
    "    df = pd.read_csv(csv_dir)\n",
    "\n",
    "    for i in tqdm(range(0,len(df))):\n",
    "        path = df.iloc[i,0]\n",
    "        im = Image.open(path).convert('L')\n",
    "\n",
    "\n",
    "def numpy_submission(sub_dir,np_dir):\n",
    "    np_file  = np.load(np_dir)\n",
    "    print(len(np_file))\n",
    "    sub_dir = pd.read_csv(sub_dir)\n",
    "    print(len(sub_dir))\n",
    "    for i in range(0,len(sub_dir)):\n",
    "        sub_dir.iloc[i,1] = np_file[i,0]\n",
    "        sub_dir.iloc[i, 2] = np_file[i, 1]\n",
    "        sub_dir.iloc[i, 3] = np_file[i, 2]\n",
    "        sub_dir.iloc[i, 4] = np_file[i, 3]\n",
    "        sub_dir.iloc[i, 5] = np_file[i, 4]\n",
    "        sub_dir.iloc[i, 6] = np_file[i, 5]\n",
    "    print(sub_dir.head())\n",
    "    sub_dir.to_csv('baseline_result.csv',index=False)\n",
    "\n",
    "\n",
    "\n",
    "    #process_images(csv_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:36:53.639243Z",
     "iopub.status.busy": "2023-08-18T07:36:53.638699Z",
     "iopub.status.idle": "2023-08-18T07:36:53.683073Z",
     "shell.execute_reply": "2023-08-18T07:36:53.682100Z",
     "shell.execute_reply.started": "2023-08-18T07:36:53.639210Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torch.nn as nn\n",
    "def set_model(opt):\n",
    "\n",
    "\n",
    "    device = opt.device\n",
    "    model = ResNet(name=opt.model,num_classes = opt.ncls)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "\n",
    "    return model, criterion\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def set_loader(opt):\n",
    "    # construct data loader\n",
    "    if opt.dataset == 'OLIVES' or opt.dataset == 'RECOVERY':\n",
    "        mean = (.1706)\n",
    "        std = (.2112)\n",
    "    else:\n",
    "        raise ValueError('dataset not supported: {}'.format(opt.dataset))\n",
    "\n",
    "    normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=224, scale=(0.2, 1.)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "\n",
    "    if opt.dataset =='OLIVES':\n",
    "        csv_path_train = opt.train_csv_path\n",
    "        csv_path_test = opt.test_csv_path\n",
    "        data_path_train = opt.train_image_path\n",
    "        data_path_test = opt.test_image_path\n",
    "        train_dataset = OLIVES(csv_path_train,data_path_train,transforms = train_transform)\n",
    "        test_dataset = RECOVERY(csv_path_test,data_path_test,transforms = val_transform)\n",
    "        train_dataset, val_dataset = random_split(train_dataset, [0.95, 0.05], generator=torch.Generator().manual_seed(42))\n",
    "    else:\n",
    "        raise ValueError(opt.dataset)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=opt.batch_size, shuffle=True,\n",
    "        num_workers=opt.num_workers, pin_memory=True)\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=1, shuffle=False,\n",
    "        num_workers=0, pin_memory=True,drop_last=False)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=1, shuffle=False,\n",
    "        num_workers=0, pin_memory=True,drop_last=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "\n",
    "def adjust_learning_rate(args, optimizer, epoch):\n",
    "    lr = args.learning_rate\n",
    "    if args.cosine:\n",
    "        eta_min = lr * (args.lr_decay_rate ** 3)\n",
    "        lr = eta_min + (lr - eta_min) * (\n",
    "                1 + math.cos(math.pi * epoch / args.epochs)) / 2\n",
    "    else:\n",
    "        steps = np.sum(epoch > np.asarray(args.lr_decay_epochs))\n",
    "        if steps > 0:\n",
    "            lr = lr * (args.lr_decay_rate ** steps)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def warmup_learning_rate(args, epoch, batch_id, total_batches, optimizer):\n",
    "    if args.warm and epoch <= args.warm_epochs:\n",
    "        p = (batch_id + (epoch - 1) * total_batches) / \\\n",
    "            (args.warm_epochs * total_batches)\n",
    "        lr = args.warmup_from + p * (args.warmup_to - args.warmup_from)\n",
    "\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def set_optimizer(opt, model):\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(),\n",
    "                          lr=opt.learning_rate,\n",
    "                          momentum=opt.momentum,\n",
    "                          weight_decay=opt.weight_decay)\n",
    "\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def save_model(model, optimizer, opt, epoch, save_file):\n",
    "    print('==> Saving...')\n",
    "    state = {\n",
    "        'opt': opt,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "    }\n",
    "    torch.save(state, save_file)\n",
    "    del state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:36:53.690932Z",
     "iopub.status.busy": "2023-08-18T07:36:53.688511Z",
     "iopub.status.idle": "2023-08-18T07:36:53.716279Z",
     "shell.execute_reply": "2023-08-18T07:36:53.715359Z",
     "shell.execute_reply.started": "2023-08-18T07:36:53.690888Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# config.py\n",
    "\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "\n",
    "def parse_option(string):\n",
    "    parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "    parser.add_argument('--print_freq', type=int, default=10,\n",
    "                        help='print frequency')\n",
    "    parser.add_argument('--save_freq', type=int, default=50,\n",
    "                        help='save frequency')\n",
    "    parser.add_argument('--batch_size', type=int, default=128,\n",
    "                        help='batch_size')\n",
    "    parser.add_argument('--num_workers', type=int, default=8,\n",
    "                        help='num of workers to use')\n",
    "    parser.add_argument('--epochs', type=int, default=100,\n",
    "                        help='number of training epochs')\n",
    "    parser.add_argument('--device', type=str, default='cuda:0')\n",
    "    # optimization\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.05,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--patient_lambda', type=float, default=1,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--cluster_lambda', type=float, default=1,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--lr_decay_epochs', type=str, default='100',\n",
    "                        help='where to decay lr, can be a list')\n",
    "    parser.add_argument('--lr_decay_rate', type=float, default=0.1,\n",
    "                        help='decay rate for learning rate')\n",
    "    parser.add_argument('--weight_decay', type=float, default=1e-4,\n",
    "                        help='weight decay')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                        help='momentum')\n",
    "    parser.add_argument('--train_csv_path', type=str, default='train data csv')\n",
    "    parser.add_argument('--test_csv_path', type=str, default='test data csv')\n",
    "    parser.add_argument('--train_image_path', type=str, default='train data csv')\n",
    "    parser.add_argument('--test_image_path', type=str, default='test data csv')\n",
    "\n",
    "    parser.add_argument('--parallel', type=int, default=1, help='data parallel')\n",
    "    parser.add_argument('--ncls', type=int, default=6, help='Number of Classes')\n",
    "    # model dataset\n",
    "    parser.add_argument('--model', type=str, default='resnet101')\n",
    "    parser.add_argument('--dataset', type=str, default='TREX_DME',\n",
    "                        choices=[ 'OLIVES'], help='dataset')\n",
    "    parser.add_argument('--mean', type=str, help='mean of dataset in path in form of str tuple')\n",
    "    parser.add_argument('--std', type=str, help='std of dataset in path in form of str tuple')\n",
    "    parser.add_argument('--data_folder', type=str, default=None, help='path to custom dataset')\n",
    "    parser.add_argument('--size', type=int, default=128, help='parameter for RandomResizedCrop')\n",
    "\n",
    "    # temperature\n",
    "    parser.add_argument('--temp', type=float, default=0.07,\n",
    "                        help='temperature for loss function')\n",
    "\n",
    "\n",
    "\n",
    "    opt = parser.parse_args(string)\n",
    "\n",
    "    # check if dataset is path that passed required arguments\n",
    "    if opt.dataset == 'path':\n",
    "        assert opt.data_folder is not None \\\n",
    "               and opt.mean is not None \\\n",
    "               and opt.std is not None\n",
    "\n",
    "    # set the path according to the environment\n",
    "    if opt.data_folder is None:\n",
    "        opt.data_folder = './datasets/'\n",
    "    opt.model_path = './save/{}_models'.format(opt.dataset)\n",
    "\n",
    "    iterations = opt.lr_decay_epochs.split(',')\n",
    "    opt.lr_decay_epochs = list([])\n",
    "    for it in iterations:\n",
    "        opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "    opt.model_name = '{}_lr_{}_decay_{}_bsz_{}_temp_{}'. \\\n",
    "        format(opt.model, opt.learning_rate,\n",
    "               opt.weight_decay, opt.batch_size, opt.temp)\n",
    "\n",
    "\n",
    "    opt.save_folder = os.path.join(opt.model_path, opt.model_name)\n",
    "    if not os.path.isdir(opt.save_folder):\n",
    "        os.makedirs(opt.save_folder)\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:36:53.722881Z",
     "iopub.status.busy": "2023-08-18T07:36:53.721051Z",
     "iopub.status.idle": "2023-08-18T07:36:53.738373Z",
     "shell.execute_reply": "2023-08-18T07:36:53.737588Z",
     "shell.execute_reply.started": "2023-08-18T07:36:53.722810Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_supervised(train_loader, model,criterion, optimizer, epoch, opt):\n",
    "    \"\"\"one epoch training\"\"\"\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    device = opt.device\n",
    "    end = time.time()\n",
    "    correct_predictions = 0\n",
    "    print(\"Inside training\")\n",
    "    for idx, (image, bio_tensor) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        images = image.to(device)\n",
    "\n",
    "        labels = bio_tensor.float()\n",
    "\n",
    "        labels = labels.to(device)\n",
    "        bsz = labels.shape[0]\n",
    "\n",
    "        # compute loss\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        predicted_labels = torch.round(torch.sigmoid(output)) \n",
    "        correct_predictions += (predicted_labels == labels).sum().item()\n",
    "\n",
    "        # update metric\n",
    "        losses.update(loss.item(), bsz)\n",
    "\n",
    "        # SGD\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # print info\n",
    "        if (idx + 1) % opt.print_freq == 0:\n",
    "            print('Train: [{0}][{1}/{2}]\\t'.format(\n",
    "                epoch, idx + 1, len(train_loader)))\n",
    "\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    total_values = len(train_loader.dataset) * 6\n",
    "    training_accuracy = (correct_predictions / total_values) * 100.0\n",
    "    print(f\"Training Accuracy: {training_accuracy:.2f}%\")\n",
    "    \n",
    "    return losses.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:36:53.745746Z",
     "iopub.status.busy": "2023-08-18T07:36:53.742958Z",
     "iopub.status.idle": "2023-08-18T07:36:53.756739Z",
     "shell.execute_reply": "2023-08-18T07:36:53.755800Z",
     "shell.execute_reply.started": "2023-08-18T07:36:53.745713Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def submission_generate(val_loader, model, opt):\n",
    "    \"\"\"validation\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    device = opt.device\n",
    "    out_list = []\n",
    "    with torch.no_grad():\n",
    "        for idx, image in (enumerate(val_loader)):\n",
    "\n",
    "            images = image.float().to(device)\n",
    "\n",
    "            # forward\n",
    "            output = model(images)\n",
    "            output = torch.round(torch.sigmoid(output))\n",
    "            out_list.append(output.squeeze().detach().cpu().numpy())\n",
    "\n",
    "\n",
    "    out_submisison = np.array(out_list)\n",
    "    np.save('output',out_submisison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T09:39:41.894415Z",
     "iopub.status.busy": "2023-08-18T09:39:41.894046Z",
     "iopub.status.idle": "2023-08-18T09:39:41.906193Z",
     "shell.execute_reply": "2023-08-18T09:39:41.905144Z",
     "shell.execute_reply.started": "2023-08-18T09:39:41.894383Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def sample_evaluation(val_loader, model, opt):\n",
    "    \"\"\"validation\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    device = opt.device\n",
    "    out_list = []\n",
    "    label_list = []\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (image,bio_tensor) in (enumerate(val_loader)):\n",
    "\n",
    "            images = image.float().to(device)\n",
    "            labels = bio_tensor.float()\n",
    "\n",
    "            labels = labels.float()\n",
    "\n",
    "            label_list.append(labels.squeeze().detach().cpu().numpy())\n",
    "            # forward\n",
    "            output = model(images)\n",
    "            output = torch.round(torch.sigmoid(output))\n",
    "            out_list.append(output.squeeze().detach().cpu().numpy())\n",
    "            \n",
    "            correct_count += (labels.to(device) == output.to(device)).sum()\n",
    "            total_count += len(labels)\n",
    "        \n",
    "    print((correct_count / total_count) * 100, \"%\")\n",
    "\n",
    "    label_array = np.array(label_list)\n",
    "    out_array = np.array(out_list)\n",
    "    f = f1_score(label_array,out_array,average='macro')\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T09:55:00.343857Z",
     "iopub.status.busy": "2023-08-18T09:55:00.342908Z",
     "iopub.status.idle": "2023-08-18T09:55:00.352435Z",
     "shell.execute_reply": "2023-08-18T09:55:00.351140Z",
     "shell.execute_reply.started": "2023-08-18T09:55:00.343823Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "args = args = ['--batch_size', '64', '--model', \"resnet101\", '--dataset', 'OLIVES', '--epochs', '30', '--device', 'cuda:0', '--train_image_path', 'E:/Backup/My backup/Project Files/Competitions/VIPCup/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TRAIN/OLIVES', '--test_image_path', 'E:/Backup/My backup/Project Files/Competitions/VIPCup/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/', '--test_csv_path', 'E:/Backup/My backup/Project Files/Competitions/VIPCup/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/test_set_submission_template.csv', '--train_csv_path', 'E:/Backup/My backup/Project Files/Competitions/VIPCup/kaggle/input/olives-training-labels/Training_Biomarker_Data.csv']\n",
    "opt = parse_option(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:36:53.803205Z",
     "iopub.status.busy": "2023-08-18T07:36:53.800711Z",
     "iopub.status.idle": "2023-08-18T07:36:53.909478Z",
     "shell.execute_reply": "2023-08-18T07:36:53.908611Z",
     "shell.execute_reply.started": "2023-08-18T07:36:53.803173Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# build data loader\n",
    "train_loader, val_loader, test_loader = set_loader(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:36:53.915698Z",
     "iopub.status.busy": "2023-08-18T07:36:53.913511Z",
     "iopub.status.idle": "2023-08-18T07:36:57.908772Z",
     "shell.execute_reply": "2023-08-18T07:36:57.907780Z",
     "shell.execute_reply.started": "2023-08-18T07:36:53.915663Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# build model and criterion\n",
    "model, criterion = set_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:36:57.910702Z",
     "iopub.status.busy": "2023-08-18T07:36:57.910323Z",
     "iopub.status.idle": "2023-08-18T07:36:57.917064Z",
     "shell.execute_reply": "2023-08-18T07:36:57.916030Z",
     "shell.execute_reply.started": "2023-08-18T07:36:57.910668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# build optimizer\n",
    "optimizer = set_optimizer(opt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T09:55:06.815057Z",
     "iopub.status.busy": "2023-08-18T09:55:06.814359Z",
     "iopub.status.idle": "2023-08-18T10:30:11.734561Z",
     "shell.execute_reply": "2023-08-18T10:30:11.733482Z",
     "shell.execute_reply.started": "2023-08-18T09:55:06.815023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# training routine\n",
    "for epoch in range(1, opt.epochs + 1):\n",
    "    train_supervised(train_loader, model, criterion, optimizer, epoch, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T10:32:49.037082Z",
     "iopub.status.busy": "2023-08-18T10:32:49.036669Z",
     "iopub.status.idle": "2023-08-18T10:32:49.988730Z",
     "shell.execute_reply": "2023-08-18T10:32:49.987697Z",
     "shell.execute_reply.started": "2023-08-18T10:32:49.037045Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_file = os.path.join(opt.save_folder, 'last.pth')\n",
    "save_model(model, optimizer, opt, opt.epochs, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T10:32:53.688844Z",
     "iopub.status.busy": "2023-08-18T10:32:53.688471Z",
     "iopub.status.idle": "2023-08-18T10:33:02.306620Z",
     "shell.execute_reply": "2023-08-18T10:33:02.305418Z",
     "shell.execute_reply.started": "2023-08-18T10:32:53.688810Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Validation\n",
    "sample_evaluation(val_loader, model, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T10:33:30.870920Z",
     "iopub.status.busy": "2023-08-18T10:33:30.870428Z",
     "iopub.status.idle": "2023-08-18T10:34:34.149564Z",
     "shell.execute_reply": "2023-08-18T10:34:34.148548Z",
     "shell.execute_reply.started": "2023-08-18T10:33:30.870873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission_generate(test_loader, model, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T10:34:34.152030Z",
     "iopub.status.busy": "2023-08-18T10:34:34.151689Z",
     "iopub.status.idle": "2023-08-18T10:34:34.204795Z",
     "shell.execute_reply": "2023-08-18T10:34:34.203899Z",
     "shell.execute_reply.started": "2023-08-18T10:34:34.151996Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output = np.load('/kaggle/working/output.npy')\n",
    "submission = pd.read_csv(\"/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/test_set_submission_template.csv\")\n",
    "submission.iloc[:, 1:] = output\n",
    "submission.to_csv(\"/kaggle/working/submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aimslab)",
   "language": "python",
   "name": "aimslab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
